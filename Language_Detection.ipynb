{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "azlMlZNqlf_D"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MK2XpPZolzV-"
   },
   "outputs": [],
   "source": [
    "# Reading the data using pandas.\n",
    "df = pd.read_csv('Languages_detection_22000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "EHNonZlxmxFS",
    "outputId": "828d0041-d116-45de-d11e-7e26414536aa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>klement gottwaldi surnukeha palsameeriti ning ...</td>\n",
       "      <td>Estonian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sebes joseph pereira thomas  på eng the jesuit...</td>\n",
       "      <td>Swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...</td>\n",
       "      <td>Thai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...</td>\n",
       "      <td>Tamil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>de spons behoort tot het geslacht haliclona en...</td>\n",
       "      <td>Dutch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Language\n",
       "0  klement gottwaldi surnukeha palsameeriti ning ...  Estonian\n",
       "1  sebes joseph pereira thomas  på eng the jesuit...   Swedish\n",
       "2  ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...      Thai\n",
       "3  விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...     Tamil\n",
       "4  de spons behoort tot het geslacht haliclona en...     Dutch"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show's first five points in data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SMdma8sQl8iX",
    "outputId": "20501e08-7b3c-42d7-80e8-40d6ce430c5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22000 entries, 0 to 21999\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Text      22000 non-null  object\n",
      " 1   Language  22000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 343.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Information regarding the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wwe3kms2JtNH",
    "outputId": "18cce9e0-ec66-4ab3-df1e-23bdc6a8d04e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Language\n",
       "Estonian      1000\n",
       "Swedish       1000\n",
       "English       1000\n",
       "Russian       1000\n",
       "Romanian      1000\n",
       "Persian       1000\n",
       "Pushto        1000\n",
       "Spanish       1000\n",
       "Hindi         1000\n",
       "Korean        1000\n",
       "Chinese       1000\n",
       "French        1000\n",
       "Portugese     1000\n",
       "Indonesian    1000\n",
       "Urdu          1000\n",
       "Latin         1000\n",
       "Turkish       1000\n",
       "Japanese      1000\n",
       "Dutch         1000\n",
       "Tamil         1000\n",
       "Thai          1000\n",
       "Arabic        1000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counts number of points having the same label\n",
    "df[\"Language\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nBWzW43jmy2c",
    "outputId": "0371d5e7-a30e-4570-806a-ea09faac9890"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Estonian', 'Swedish', 'Thai', 'Tamil', 'Dutch', 'Japanese',\n",
       "       'Turkish', 'Latin', 'Urdu', 'Indonesian', 'Portugese', 'French',\n",
       "       'Chinese', 'Korean', 'Hindi', 'Spanish', 'Pushto', 'Persian',\n",
       "       'Romanian', 'Russian', 'English', 'Arabic'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeing how many unique classes are there\n",
    "df['Language'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9d3C8mt0yynp"
   },
   "outputs": [],
   "source": [
    "# labels_to_remove = ['Estonian', 'Swedish', 'Thai', 'Dutch', 'Japanese','Turkish', 'Latin', 'Urdu', 'Indonesian', 'Portugese', 'French','Chinese', 'Korean']\n",
    "# data = data[~data['Language'].isin(labels_to_remove)]\n",
    "# data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "r9FkYPWl4eOr"
   },
   "outputs": [],
   "source": [
    "# Code for dropping data points based on percentage.\n",
    "percentage_to_remove = 0.85\n",
    "\n",
    "# Group the DataFrame by 'Label'\n",
    "groups = df.groupby('Language')\n",
    "\n",
    "# List to hold modified groups\n",
    "modified_groups = []\n",
    "\n",
    "# Iterate through each group\n",
    "for label, group in groups:\n",
    "    num_to_remove = int(len(group) * percentage_to_remove)\n",
    "\n",
    "    if num_to_remove > 0:\n",
    "        indices_to_remove = np.random.choice(group.index, num_to_remove, replace=False)\n",
    "        modified_group = group.drop(indices_to_remove)\n",
    "        modified_groups.append(modified_group)\n",
    "\n",
    "# Concatenate modified groups back together\n",
    "data = pd.concat(modified_groups)\n",
    "data.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ty88iNaJ4u4L",
    "outputId": "3ef4332a-4988-43b0-c4dc-c6f9b98874e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Arabic', 'Chinese', 'Dutch', 'English', 'Estonian', 'French',\n",
       "       'Hindi', 'Indonesian', 'Japanese', 'Korean', 'Latin', 'Persian',\n",
       "       'Portugese', 'Pushto', 'Romanian', 'Russian', 'Spanish', 'Swedish',\n",
       "       'Tamil', 'Thai', 'Turkish', 'Urdu'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Language'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eg8QtoGg5n7a",
    "outputId": "8846ec8c-c5bc-4263-81ea-776a6874a932"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Language\n",
       "Arabic        150\n",
       "Chinese       150\n",
       "Turkish       150\n",
       "Thai          150\n",
       "Tamil         150\n",
       "Swedish       150\n",
       "Spanish       150\n",
       "Russian       150\n",
       "Romanian      150\n",
       "Pushto        150\n",
       "Portugese     150\n",
       "Persian       150\n",
       "Latin         150\n",
       "Korean        150\n",
       "Japanese      150\n",
       "Indonesian    150\n",
       "Hindi         150\n",
       "French        150\n",
       "Estonian      150\n",
       "English       150\n",
       "Dutch         150\n",
       "Urdu          150\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Language'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ZBt2pr0QQ9Wm"
   },
   "outputs": [],
   "source": [
    "# Creating labels for each class that are available in the data.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_labels = le.fit_transform(data['Language'])\n",
    "# Create a dictionary to map labels to their original values\n",
    "label_mapping = {label: value for label, value in zip(y_labels, data['Language'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0 corresponds to element 'Arabic'\n",
      "Label 1 corresponds to element 'Chinese'\n",
      "Label 2 corresponds to element 'Dutch'\n",
      "Label 3 corresponds to element 'English'\n",
      "Label 4 corresponds to element 'Estonian'\n",
      "Label 5 corresponds to element 'French'\n",
      "Label 6 corresponds to element 'Hindi'\n",
      "Label 7 corresponds to element 'Indonesian'\n",
      "Label 8 corresponds to element 'Japanese'\n",
      "Label 9 corresponds to element 'Korean'\n",
      "Label 10 corresponds to element 'Latin'\n",
      "Label 11 corresponds to element 'Persian'\n",
      "Label 12 corresponds to element 'Portugese'\n",
      "Label 13 corresponds to element 'Pushto'\n",
      "Label 14 corresponds to element 'Romanian'\n",
      "Label 15 corresponds to element 'Russian'\n",
      "Label 16 corresponds to element 'Spanish'\n",
      "Label 17 corresponds to element 'Swedish'\n",
      "Label 18 corresponds to element 'Tamil'\n",
      "Label 19 corresponds to element 'Thai'\n",
      "Label 20 corresponds to element 'Turkish'\n",
      "Label 21 corresponds to element 'Urdu'\n"
     ]
    }
   ],
   "source": [
    "# Print the mapping\n",
    "for label, value in label_mapping.items():\n",
    "    print(f\"Label {label} corresponds to element '{value}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(le, open('models/labelencoder.pkl', 'wb'))\n",
    "load_model = pickle.load(open('models/labelencoder.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "2Hf2zk2oq6SG"
   },
   "outputs": [],
   "source": [
    "# Preprocessing the data before vectorizing it\n",
    "# Removing punctuation, Numeric digits, converting to lowercases.\n",
    "X = []\n",
    "for i in range (len(data)):\n",
    "  sentence = data['Text'][i]\n",
    "  translation_table = str.maketrans(\"\", \"\", string.punctuation)\n",
    "  cleaned_sentence = sentence.translate(translation_table)\n",
    "  lowercase_string = cleaned_sentence.lower()\n",
    "  X.append(lowercase_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "EbtQYFMVnJet"
   },
   "outputs": [],
   "source": [
    "# X = []\n",
    "# for text in data['Text']:\n",
    "#   text = re.sub(r'[!@#$(),\\n\"%^&*:;~0-9]', ' ',text)\n",
    "#   text = re.sub('[[]]',' ',text)\n",
    "#   text = text.lower()\n",
    "#   X.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "WgNweOuILXRY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"D:\\Apps\\Python\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\ramja\\AppData\\Local\\Temp\\ipykernel_15312\\1781769951.py\", line 5, in <module>\n",
      "    X_vec = xd.toarray()\n",
      "            ^^^^^^^^^^^^\n",
      "  File \"D:\\Apps\\Python\\Lib\\site-packages\\scipy\\sparse\\_compressed.py\", line 1050, in toarray\n",
      "    out = self._process_toarray_args(order, out)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Apps\\Python\\Lib\\site-packages\\scipy\\sparse\\_base.py\", line 1267, in _process_toarray_args\n",
      "    return np.zeros(self.shape, dtype=self.dtype, order=order)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.72 GiB for an array with shape (3300, 69857) and data type int64\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Apps\\Python\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Apps\\Python\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1428, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Apps\\Python\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1319, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Apps\\Python\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1172, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Apps\\Python\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1062, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Apps\\Python\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1114, in get_records\n",
      "    style = stack_data.style_with_executing_node(style, self._tb_highlight)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Apps\\Python\\Lib\\site-packages\\stack_data\\core.py\", line 455, in style_with_executing_node\n",
      "    class NewStyle(style):\n",
      "  File \"D:\\Apps\\Python\\Lib\\site-packages\\pygments\\style.py\", line 91, in __new__\n",
      "    ndef[4] = colorformat(styledef[3:])\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Apps\\Python\\Lib\\site-packages\\pygments\\style.py\", line 58, in colorformat\n",
      "    assert False, \"wrong color format %r\" % text\n",
      "AssertionError: wrong color format 'ansiyellow'\n"
     ]
    }
   ],
   "source": [
    "#Using CountVectorizer to vectorize the data.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "xd = vectorizer.fit_transform(X)\n",
    "X_vec = xd.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(vectorizer, open('models/count_vectorizer.pkl', 'wb'))\n",
    "load_model = pickle.load(open('models/count_vectorizer.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w0Ux8LTsu98N"
   },
   "outputs": [],
   "source": [
    "# Spliting the data into Train, Test and Cross Validation.\n",
    "X_train,X_cvt,y_train,y_cvt = train_test_split(X_vec,y_labels,test_size = 0.4)\n",
    "X_test,X_cv,y_test,y_cv = train_test_split(X_cvt,y_cvt,test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "mX0pDD_xs1xs",
    "outputId": "d7260492-4487-45ad-f64b-0f4eeb8d9425"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9_Cdmo1ySTPp"
   },
   "outputs": [],
   "source": [
    "y_pred =  model.predict(X_test)\n",
    "y_pred_cv =  model.predict(X_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PTovVaUBVZBQ",
    "outputId": "650f205b-5547-4772-a9c6-aa55fd9b0a44"
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy_cv = accuracy_score(y_cv, y_pred_cv)\n",
    "print(\"accuracies for test data: \",accuracy)\n",
    "print(\"accuracies for cv data: \",accuracy_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "0qeUZFitI4hM",
    "outputId": "8dda507f-ced3-4b5d-aada-f73cce3c7a38"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_pred, y_test)\n",
    "\n",
    "# Create a heatmap of the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8dHXNoNHdihE"
   },
   "outputs": [],
   "source": [
    "def predictions(text):\n",
    "  x_vecd = vectorizer.transform([text])\n",
    "  X_vec = x_vecd.toarray()\n",
    "  pred = model.predict(X_vec)\n",
    "  pred = le.inverse_transform(pred)\n",
    "  print(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eAsp7jezdh0H",
    "outputId": "653e66e2-3c69-4c0e-df52-1ca0bb003b80"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11940\\978065242.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"हाय, दिन कैसा रहा? \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "predictions(\"हाय, दिन कैसा रहा? \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'models/Language_Detection_model.pkl'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    "load_model = pickle.load(open(filename, 'rb'))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
